{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "339e0883-1a76-4547-899b-5d7a3753b61d",
     "showTitle": true,
     "title": "Mount Bucket"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import urllib\n",
    "\n",
    "\n",
    "file_type = \"csv\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "aws_keys_df = spark.read.format(file_type)\\\n",
    ".option(\"header\", first_row_is_header)\\\n",
    ".option(\"sep\", delimiter)\\\n",
    ".load(\"/FileStore/tables/authentication_credentials.csv\")\n",
    "\n",
    "ACCESS_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Secret access key').collect()[0]['Secret access key']\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")\n",
    "\n",
    "AWS_S3_BUCKET = \"user-0ea903d23769-bucket\"\n",
    "MOUNT_NAME = \"/mnt/0ea903d23769-bucket\"\n",
    "SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "dbutils.fs.mount(SOURCE_URL, MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Topic Contents Into Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1e936b7-4aee-440e-8f88-2941359294ab",
     "showTitle": true,
     "title": "Read Topic Contents Into Dataframes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_data(spark, file_type, infer_schema, location):\n",
    "    return spark.read.format(file_type) \\\n",
    "                    .option(\"inferSchema\", infer_schema) \\\n",
    "                    .load(location)\n",
    "\n",
    "file_type = \"json\"\n",
    "infer_schema = \"true\"\n",
    "\n",
    "location_pin = \"/mnt/0ea903d23769-bucket/topics/0ea903d23769.pin/partition=0/*.json\"\n",
    "location_geo = \"/mnt/0ea903d23769-bucket/topics/0ea903d23769.geo/partition=0/*.json\"\n",
    "location_user = \"/mnt/0ea903d23769-bucket/topics/0ea903d23769.user/partition=0/*.json\"\n",
    "\n",
    "df_pin_dirty = read_data(spark, file_type, infer_schema, location_pin)\n",
    "df_geo_dirty = read_data(spark, file_type, infer_schema, location_geo)\n",
    "df_user_dirty = read_data(spark, file_type, infer_schema, location_user)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dirty CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e69de66-a78d-4f5c-8b97-5e1ca6aa77c8",
     "showTitle": true,
     "title": "Download Dirty CSVs"
    }
   },
   "outputs": [],
   "source": [
    "# df_pin.write.csv('FileStore/tables/pin_dirty.csv')\n",
    "# df_geo.write.csv('FileStore/tables/geo_dirty.csv')\n",
    "# df_user.write.csv('FileStore/tables/user_dirty.csv')\n",
    "\n",
    "display(df_pin_dirty.select(\"*\"))\n",
    "display(df_geo_dirty.select(\"*\"))\n",
    "display(df_use_dirty.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e5ebb5c-fca2-4e14-9586-fd21689cc305",
     "showTitle": true,
     "title": "Create Spark Session"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType, TimestampType, DateType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DF Cleaning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning df_pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "518f3b54-750d-49d4-982c-0d588b6732bb",
     "showTitle": true,
     "title": "Cleaning df_pin"
    }
   },
   "outputs": [],
   "source": [
    "df_pin = df_pin_dirty\n",
    "\n",
    "# Replace empty entries and entries with no relevant data in each column with Nones\n",
    "df_pin = df_pin.replace(['', ' ', 'NULL', 'null'], [None] * 4)\n",
    "df_pin = df_pin.withColumn(\"description\", when(col(\"description\") == \"No description available Story format\", None).otherwise(col(\"description\")))\n",
    "df_pin = df_pin.withColumn(\"follower_count\", when(col(\"follower_count\") == \"User Info Error\", None).otherwise(col(\"follower_count\")))\n",
    "df_pin = df_pin.withColumn(\"image_src\", when(col(\"image_src\") == \"Image src error.\", None).otherwise(col(\"image_src\")))\n",
    "df_pin = df_pin.withColumn(\"poster_name\", when(col(\"poster_name\") == \"User Info Error\", None).otherwise(col(\"poster_name\")))\n",
    "df_pin = df_pin.withColumn(\"tag_list\", when(col(\"tag_list\") == \"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\", None).otherwise(col(\"tag_list\")))\n",
    "df_pin = df_pin.withColumn(\"title\", when(col(\"title\") == \"No Title Data Available\", None).otherwise(col(\"title\")))\n",
    "\n",
    "# Transform follower_count to ensure every entry is a number and data type is an int\n",
    "# Remove any non-numeric characters (like 'k' in '136k') and then convert to integer\n",
    "df_pin = df_pin.withColumn(\"follower_count\", regexp_replace(col(\"follower_count\"), \"[^0-9]\", \"\"))\n",
    "df_pin = df_pin.withColumn(\"follower_count\", col(\"follower_count\").cast(IntegerType()))\n",
    "\n",
    "# Ensure that each column containing numeric data has a numeric data type\n",
    "df_pin = df_pin.withColumn(\"downloaded\", col(\"downloaded\").cast(IntegerType()))\n",
    "\n",
    "# Clean the data in the save_location column to include only the save location path\n",
    "df_pin = df_pin.withColumn(\"save_location\", regexp_replace(col(\"save_location\"), \"Local save in \", \"\"))\n",
    "\n",
    "# Rename the index column to ind\n",
    "df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "df_pin = df_pin.select([\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \"save_location\", \"category\"])\n",
    "\n",
    "\n",
    "display(df_pin.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning df_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10bee420-1e1d-4e8d-b2a8-6bfc9df10b7d",
     "showTitle": true,
     "title": "Cleaning df_geo"
    }
   },
   "outputs": [],
   "source": [
    "df_geo = df_geo_dirty\n",
    "\n",
    "# Create a new column 'coordinates' containing an array of latitude and longitude\n",
    "df_geo = df_geo.withColumn(\"coordinates\", array(col(\"latitude\"), col(\"longitude\")))\n",
    "\n",
    "# Drop the latitude and longitude columns\n",
    "df_geo = df_geo.drop(\"latitude\", \"longitude\")\n",
    "\n",
    "# Convert the timestamp column from a string to a timestamp data type\n",
    "df_geo = df_geo.withColumn(\"timestamp\", col(\"timestamp\").cast(TimestampType()))\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "df_geo = df_geo.select([\"ind\", \"country\", \"coordinates\", \"timestamp\"])\n",
    "\n",
    "display(df_geo.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8af842a0-f7f1-4d42-bc49-f62cbc95c4ee",
     "showTitle": true,
     "title": "Cleaning df_user"
    }
   },
   "outputs": [],
   "source": [
    "df_user = df_user_dirty\n",
    "\n",
    "# Create a new column 'user_name' by concatenating 'first_name' and 'last_name'\n",
    "df_user = df_user.withColumn(\"user_name\", concat_ws(\" \", col(\"first_name\"), col(\"last_name\")))\n",
    "\n",
    "# Drop the 'first_name' and 'last_name' columns\n",
    "df_user = df_user.drop(\"first_name\", \"last_name\")\n",
    "\n",
    "# Convert the 'date_joined' column from a string to a timestamp data type\n",
    "df_user = df_user.withColumn(\"date_joined\", col(\"date_joined\").cast(TimestampType()))\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "df_user = df_user.select([\"ind\", \"user_name\", \"age\", \"date_joined\"])\n",
    "\n",
    "display(df_user.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Most Popular Category per Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66217540-8c22-42e0-b82e-389cfbdf8023",
     "showTitle": true,
     "title": "Find Most Popular Category per Country"
    }
   },
   "outputs": [],
   "source": [
    "# Join the geo and pin DataFrames on the 'ind' column\n",
    "df_joined = df_geo.join(df_pin, \"ind\")\n",
    "\n",
    "# Group by country and category and count the occurrences\n",
    "df_category_count = df_joined.groupBy(\"country\", \"category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "\n",
    "# Find the most popular category for each country by sorting within each group\n",
    "window = Window.partitionBy(\"country\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "df_most_popular = df_category_count.withColumn(\"rank\", rank().over(window)) \\\n",
    "                                   .filter(col(\"rank\") == 1) \\\n",
    "                                   .drop(\"rank\")\n",
    "\n",
    "# Select the desired columns for the final DataFrame\n",
    "df_final = df_most_popular.select(\"country\", \"category\", \"category_count\")\n",
    "\n",
    "display(df_final.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Post Count per Category Between 2018 & 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abc27421-9c7a-4073-9c60-53c2e5302aa3",
     "showTitle": true,
     "title": "Find Post Count per Category Between 2018 & 2022"
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_pin.join(df_geo, 'ind', 'inner')\n",
    "\n",
    "# Convert the timestamp column from string to timestamp type if it's not already\n",
    "df_joined = df_joined.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "\n",
    "# Filter the DataFrame for posts between 2018 and 2022\n",
    "df_filtered = df_joined.filter((year(\"timestamp\") >= 2018) & (year(\"timestamp\") <= 2022))\n",
    "\n",
    "# Create a new column with just the year from the timestamp\n",
    "df_with_year = df_filtered.withColumn(\"post_year\", year(\"timestamp\"))\n",
    "\n",
    "# Group by post_year and category and count the occurrences\n",
    "df_category_count = df_with_year.groupBy(\"post_year\", \"category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "\n",
    "# Order the result for better readability\n",
    "df_result = df_category_count.orderBy(\"post_year\", \"category\")\n",
    "\n",
    "display(df_result.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Most Followed User per Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87a25a1-1f07-4347-b60e-395a0db70d77",
     "showTitle": true,
     "title": "Find Most Followed User per Country"
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_pin.join(df_geo, 'ind', 'inner')\n",
    "\n",
    "# Define a window spec partitioned by country\n",
    "windowSpec = Window.partitionBy(\"country\").orderBy(col(\"follower_count\").desc())\n",
    "\n",
    "# Use the window spec to add a row number for each user within each country partition\n",
    "df_ranked = df_joined.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter for the top user (row_number 1) in each country\n",
    "df_top_user_per_country = df_ranked.filter(col(\"row_number\") == 1) \\\n",
    "                                   .select(\"country\", \"poster_name\", \"follower_count\")\n",
    "\n",
    "display(df_top_user_per_country.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find The Country With Most Followed User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6960b7fa-a285-4a4e-98b3-541027570706",
     "showTitle": true,
     "title": "Find The Country With Most Followed User"
    }
   },
   "outputs": [],
   "source": [
    "# Find the maximum follower count across all countries\n",
    "max_global_follower_count = df_top_followers_per_country.agg(max(\"follower_count\")).collect()[0][0]\n",
    "\n",
    "# Find the country or countries with the user that has the maximum global follower count\n",
    "df_country_with_top_follower = df_top_followers_per_country.filter(col(\"follower_count\") == max_global_follower_count) \\\n",
    "                                                            .select(\"country\", \"follower_count\")\n",
    "\n",
    "# Display the results\n",
    "display(df_country_with_top_follower.select(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Most Popular Category per Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cf3e54d-f866-435f-b404-e2a95866decc",
     "showTitle": true,
     "title": "Find Most Popular Category per Age Group"
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_pin.join(df_user, 'ind', 'inner')\n",
    "\n",
    "# Create the age_group column\n",
    "df_with_age_group = df_joined.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"age\").between(18, 24), \"18-24\")\n",
    "    .when(col(\"age\").between(25, 35), \"25-35\")\n",
    "    .when(col(\"age\").between(36, 50), \"36-50\")\n",
    "    .otherwise(\"50+\")\n",
    ")\n",
    "\n",
    "# Group by age_group and category and count the occurrences\n",
    "df_category_count = df_with_age_group.groupBy(\"age_group\", \"category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "\n",
    "# Define a window spec partitioned by age_group and ordered by category_count descending\n",
    "windowSpec = Window.partitionBy(\"age_group\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "# Use the window spec to add a rank for each category within each age group partition\n",
    "df_ranked = df_category_count.withColumn(\"rank\", rank().over(windowSpec))\n",
    "\n",
    "# Filter for the top-ranked category within each age group\n",
    "df_top_category_per_age_group = df_ranked.filter(col(\"rank\") == 1).select(\"age_group\", \"category\", \"category_count\")\n",
    "\n",
    "display(df_top_category_per_age_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Median Follower Count per Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "857458b8-bede-48fe-b03f-0bc660d19f9d",
     "showTitle": true,
     "title": "Find Median Follower Count per Age Group"
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_pin.join(df_user, 'ind', 'inner')\n",
    "\n",
    "# Age groups\n",
    "df_with_age_group = df_joined.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"age\").between(18, 24), \"18-24\")\n",
    "    .when(col(\"age\").between(25, 35), \"25-35\")\n",
    "    .when(col(\"age\").between(36, 50), \"36-50\")\n",
    "    .otherwise(\"50+\")\n",
    ")\n",
    "\n",
    "# Group by age_group and calculate the median follower count\n",
    "df_median_follower_count = df_with_age_group.groupBy(\"age_group\")\\\n",
    "                                            .agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\"))\n",
    "\n",
    "# Display the result\n",
    "display(df_median_follower_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find New User Count Between 2015 & 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea4c292b-f3f9-490b-ae7d-49eefc4fcf9e",
     "showTitle": true,
     "title": "Find New User Count Between 2015 & 2020"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the date_joined column from string to date type\n",
    "df_user = df_user.withColumn(\"date_joined\", col(\"date_joined\").cast(DateType()))\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "df_with_year = df_user.withColumn(\"post_year\", year(col(\"date_joined\")))\n",
    "\n",
    "# Filter the DataFrame for years between 2015 and 2020\n",
    "df_filtered = df_with_year.filter((col(\"post_year\") >= 2015) & (col(\"post_year\") <= 2020))\n",
    "\n",
    "# Group by post_year and count the number of users\n",
    "df_number_users_joined = df_filtered.groupBy(\"post_year\").agg(count(\"*\").alias(\"number_users_joined\"))\n",
    "\n",
    "display(df_number_users_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Median Follower Count of Users Joined Between 2015 & 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter users who joined between 2015 and 2020\n",
    "df_filtered_users = df_user.withColumn(\"date_joined\", col(\"date_joined\").cast(\"timestamp\")) \\\n",
    "                           .withColumn(\"post_year\", year(\"date_joined\")) \\\n",
    "                           .filter((col(\"post_year\") >= 2015) & (col(\"post_year\") <= 2020))\n",
    "\n",
    "df_joined = df_filtered_users.join(df_pin, 'ind', 'inner')\n",
    "\n",
    "# Calculate the median follower count per post year\n",
    "df_median_follower_count = df_joined.groupBy(\"post_year\") \\\n",
    "                                    .agg(expr(\"percentile_approx(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "display(df_median_follower_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Median Follower Count per Joining Year & Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3d7e287-460d-4cbd-9995-61f5da40b0ec",
     "showTitle": true,
     "title": "Find Median Follower Count per Joining Year & Age Group"
    }
   },
   "outputs": [],
   "source": [
    "# Filter users who joined between 2015 and 2020\n",
    "df_users_filtered = df_user.withColumn(\"date_joined\", col(\"date_joined\").cast(\"timestamp\")) \\\n",
    "                           .withColumn(\"post_year\", year(col(\"date_joined\"))) \\\n",
    "                           .filter((col(\"post_year\") >= 2015) & (col(\"post_year\") <= 2020))\n",
    "\n",
    "# Create the age_group column\n",
    "df_users_age_grouped = df_users_filtered.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"age\").between(18, 24), \"18-24\")\n",
    "    .when(col(\"age\").between(25, 35), \"25-35\")\n",
    "    .when(col(\"age\").between(36, 50), \"36-50\")\n",
    "    .otherwise(\"50+\")\n",
    ")\n",
    "\n",
    "# Join df_users_age_grouped with df_pin on the user identifier to get follower counts\n",
    "df_joined = df_users_age_grouped.join(df_pin, 'ind', 'inner')\n",
    "\n",
    "# Group by age_group and post_year, and calculate the median follower count\n",
    "df_median_followers = df_joined.groupBy(\"age_group\", \"post_year\") \\\n",
    "                               .agg(expr(\"percentile_approx(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "display(df_median_followers)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "0ea903d23769",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
